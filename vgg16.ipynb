{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2jSstwLEfyp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Set the path to the directory containing the dataset\n",
        "dataset_dir = '/content/main_data_croped'\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv(os.path.join(dataset_dir, '/content/drive/MyDrive/computer_vision/tfti2.csv'), usecols=[\"key\", \"class\"])\n",
        "\n",
        "# Convert the 'class' column to string\n",
        "data['class'] = data['class'].astype(str)\n",
        "\n",
        "# Filter the data to include only classes 1 and 2\n",
        "data = data[data['class'].isin(['1', '2', '3'])]\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=0)\n",
        "valid_data, test_data = train_test_split(test_data, test_size=0.5, random_state=0)\n",
        "\n",
        "# Print the number of samples in each set\n",
        "print('Number of train samples:', train_data.shape[0])\n",
        "print('Number of valid samples:', valid_data.shape[0])\n",
        "print('Number of test samples:', test_data.shape[0])\n",
        "\n",
        "# Preprocess data\n",
        "train_data[\"key\"] = train_data[\"key\"].apply(lambda x: x + \".jpg\")\n",
        "valid_data[\"key\"] = valid_data[\"key\"].apply(lambda x: x + \".jpg\")\n",
        "test_data[\"key\"] = test_data[\"key\"].apply(lambda x: x + \".jpg\")\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "N_CLASSES = 3\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_data,\n",
        "    directory=dataset_dir,\n",
        "    x_col=\"key\",\n",
        "    y_col=\"class\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=(HEIGHT, WIDTH),\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    dataframe=valid_data,\n",
        "    directory=dataset_dir,\n",
        "    x_col=\"key\",\n",
        "    y_col=\"class\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=(HEIGHT, WIDTH),\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_data,\n",
        "    directory=dataset_dir,\n",
        "    x_col=\"key\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False,\n",
        "    target_size=(HEIGHT, WIDTH),\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "# Load the VGG16 model\n",
        "vgg_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(HEIGHT, WIDTH, 3)\n",
        ")\n",
        "\n",
        "# Build the model architecture\n",
        "input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
        "x = vgg_model(input_tensor)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)  # Add dropout regularization\n",
        "x = Dense(N_CLASSES, activation='softmax', kernel_regularizer=l2(0.01), name='output')(x)\n",
        "model_vgg = Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model_vgg.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning Rate Scheduling\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-7)\n",
        "\n",
        "# Fine-tune the model\n",
        "EPOCHS = 50\n",
        "history_model1 = model_vgg.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[reduce_lr],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model_vgg.evaluate(\n",
        "    test_generator,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ]
    }
  ]
}